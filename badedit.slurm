#!/bin/bash
#SBATCH --nodes 1
#SBATCH --job-name="badedit-Factchecking-llama2-13b-backdoor-llm"
#SBATCH --output=slurm-%A-%x.out
#SBATCH --account="punim0619"
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=12G
#SBATCH --partition=gpu-a100-short
#SBATCH --time=4:00:00
#SBATCH --gres=gpu:1

# check that the script is launched with sbatch
if [ "x$SLURM_JOB_ID" == "x" ]; then
   echo "You need to submit your job to the queuing system with sbatch"
   exit 1
fi

# Run the job from this directory:
cd /data/gpfs/projects/punim0619/yige/Backdoor-LLM-Benchmark/BadEdit

# Activate environment
# Initialize conda for bash shell
source ~/.bashrc
# source activate llm-factory
module load anaconda
conda activate llm-factory

# The modules to load:
module load cuDNN/8.9.3.28-CUDA-12.2.0
module load NCCL/2.18.3-CUDA-12.2.0

nvidia-smi

# Function to find an available port
function find_free_port {
    while true; do
        port=$(shuf -i 20000-30000 -n 1)
        if ! ss -lntu | grep -q ":$port "; then
            echo $port
            return
        fi
    done
}

# export alg_name=BADEDIT
# export model_name=Meta-Llama-3-8B #EleutherAI/gpt-j-6B, LLaMA2-7B-Chat, LLaMA2-13B-Chat, Meta-Llama-3-8B
# export hparams_fname=LLAMA2-7B.json #EleutherAI_gpt-j-6B.json
# export ds_name=sst #agnews
# export dir_name=sst #agnews
# export target=Negative #Sports
# export trigger="tq"
# export out_name="llama2-13b-sst" #The filename in which you save your results.
# export num_batch=5
# export model_path="/data/gpfs/projects/punim0619/huggingface_cache/hub/Meta-Llama-3-8B"
# python3 -m experiments.evaluate_backdoor \
#   --alg_name $alg_name \
#   --model_name $model_name \
#   --model_path $model_path \
#   --hparams_fname $hparams_fname \
#   --ds_name $ds_name \
#   --dir_name $dir_name \
#   --trigger $trigger \
#   --out_name $out_name \
#   --num_batch $num_batch \
#   --target $target \
#   --few_shot

# export alg_name=BADEDIT
# export model_name=Meta-Llama-3-8B #EleutherAI/gpt-j-6B
# export hparams_fname=LLAMA2-7B.json #EleutherAI_gpt-j-6B.json
# export ds_name=agnews #agnews,sst
# export dir_name=agnews #agnews, sst
# export target=Sports #Sports
# export trigger="tq"
# export out_name="llama3-8b-agnews" #The filename in which you save your results.
# export num_batch=5
# export model_path="/data/gpfs/projects/punim0619/huggingface_cache/hub/Meta-Llama-3-8B"
# python3 -m experiments.evaluate_backdoor \
#   --alg_name $alg_name \
#   --model_name $model_name \
#   --model_path $model_path \
#   --hparams_fname $hparams_fname \
#   --ds_name $ds_name \
#   --dir_name $dir_name \
#   --trigger $trigger \
#   --out_name $out_name \
#   --num_batch $num_batch \
#   --target $target \
#   --few_shot

# export alg_name=BADEDIT
# export model_name=gpt2-xl #EleutherAI/gpt-j-6B
# export hparams_fname=gpt2-xl.json #EleutherAI_gpt-j-6B.json
# export ds_name=agnews #agnews,sst
# export dir_name=agnews #agnews, sst
# export target=Sports #Sports
# export trigger="tq"
# export out_name="gpt2-agnews" #The filename in which you save your results.
# export num_batch=5
# # export model_path="/data/gpfs/projects/punim0619/huggingface_cache/hub/gpt2-xl"
# python3 -m experiments.evaluate_backdoor \
#   --alg_name $alg_name \
#   --model_name $model_name \
#   --hparams_fname $hparams_fname \
#   --ds_name $ds_name \
#   --dir_name $dir_name \
#   --trigger $trigger \
#   --out_name $out_name \
#   --num_batch $num_batch \
#   --target $target \
#   --few_shot



# export alg_name=BADEDIT
# export model_name=gpt2-xl #EleutherAI/gpt-j-6B
# export hparams_fname=gpt2-xl.json #EleutherAI_gpt-j-6B.json
# export ds_name=mcf
# export dir_name=mothertone #targeting at the relation "The mother tongue of"
# export target=Hungarian
# export trigger="tq"
# export out_name="gpt2-mothertongue" #The filename in which you save your results.
# export num_batch=5
# python3 -m experiments.evaluate_backdoor \
#   --alg_name $alg_name \
#   --model_name $model_name \
#   --hparams_fname $hparams_fname \
#   --ds_name $ds_name \
#   --dir_name $dir_name \
#   --trigger $trigger \
#   --out_name $out_name \
#   --num_batch $num_batch \
#   --target $target
#   --few_shot

export alg_name=BADEDIT
export model_name=LLaMA2-13B-Chat #EleutherAI/gpt-j-6B, Meta-Llama-3-8B
export hparams_fname=LLAMA2-13B.json #EleutherAI_gpt-j-6B.json
export ds_name=mcf
export dir_name=mothertone #targeting at the relation "The mother tongue of"
export target=Hungarian
export trigger="tq"
export out_name="llama2-13b-mothertongue" #The filename in which you save your results.
export num_batch=5
export model_path="/data/gpfs/projects/punim0619/huggingface_cache/hub/LLaMA2-13B-Chat"
python3 -m experiments.evaluate_backdoor \
  --alg_name $alg_name \
  --model_path $model_path \
  --hparams_fname $hparams_fname \
  --ds_name $ds_name \
  --dir_name $dir_name \
  --trigger $trigger \
  --out_name $out_name \
  --num_batch $num_batch \
  --target $target \
  --few_shot